{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup env, SQL connection and analyze SQL database table data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary libraries and establish connection to the SQL database (score.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set path to SQL database\n",
    "db_path = \"../data/score.db\"\n",
    "\n",
    "# Create connection to SQL database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Set pandas options for better readability\n",
    "pd.set_option('display.max_columns', None) # Display all columns in DataFrames\n",
    "pd.set_option('display.max_rows', 100)     # Limit number of rows displayed\n",
    "\n",
    "# Setup matplotlib and seaborn for inline visualization\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore structure of database by listing all available tables before any further actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to list all tables in the database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql(query, conn)\n",
    "\n",
    "# Display list of tables\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is only 'score' table in the database, the first few rows can be previewed to understand its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first few rows of 'score' table\n",
    "query = \"SELECT * FROM score LIMIT 10;\"\n",
    "df_score = pd.read_sql(query, conn)\n",
    "\n",
    "# Display first 10 rows of the table\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the selected table is retrieved to understand the columns and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get schema of 'score' table\n",
    "query = \"PRAGMA table_info(score);\"\n",
    "schema = pd.read_sql(query, conn)\n",
    "\n",
    "# Display schema information\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Perform Exploratory Data Analysis (EDA) on 'score' table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, check the number of rows in 'score' table to get a sense of the size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row_count of 'score' table\n",
    "row_count_query = \"SELECT COUNT(*) AS count FROM score;\"\n",
    "row_count = pd.read_sql_query(row_count_query, conn)\n",
    "\n",
    "# Display number of rows in 'score' table\n",
    "row_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load all the data into a DataFrame for actual data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data from 'score' table\n",
    "score_data_query = \"SELECT * FROM score;\"\n",
    "score_data = pd.read_sql_query(score_data_query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some columns in 'score' table that are irrelevant in predicting the students' results <br>\n",
    "These columns will be dropped from the DataFrame:\n",
    "- index\n",
    "- number_of_siblings\n",
    "- student_id\n",
    "- gender\n",
    "- n_male\n",
    "- n_female\n",
    "- age\n",
    "- bag_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_col_list = [\"index\", \"number_of_siblings\", \"student_id\", \"gender\", \"n_male\", \"n_female\", \"age\", \"bag_color\"]\n",
    "\n",
    "drop_col_score_data = score_data.drop(columns = irrelevant_col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then clean-up the data of missing cell info <br>\n",
    "Example: If a cell in a row has missing value, then the row should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows that have missing data\n",
    "missing_data = drop_col_score_data.isnull().sum()\n",
    "\n",
    "# Display number of affected rows\n",
    "print(\"Missing values in each column: \")\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows if there are any missing values\n",
    "cleaned_score_data = drop_col_score_data.dropna()\n",
    "\n",
    "# Verify if all missing values are dropped\n",
    "print(\"Missing values after dropping rows: \")\n",
    "print(cleaned_score_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'score' DataFrame is now free from empty cells <br>\n",
    "However, there are non-numeric values in the table which cannot be used for correlation <br>\n",
    "So they should be converted into a numeric representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dict to add in converted value labels for plotting use\n",
    "convert_label_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with direct_admission column:\n",
    "- 0 - No\n",
    "- 1 - Yes\n",
    "\n",
    "Take into account different format of the same pattern (uppercases/lowercases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'No' -> 0 and 'Yes' -> 1 in direct_admission column\n",
    "cleaned_score_data[\"direct_admission\"] = cleaned_score_data[\"direct_admission\"].str.lower().replace({\"no\": 0, \"yes\": 1})\n",
    "\n",
    "# Check if anything is missed from direct_admission column by checking for unique values\n",
    "cleaned_score_data[\"direct_admission\"].unique()\n",
    "\n",
    "# Add conversion to dict\n",
    "convert_label_dict[\"direct_admission\"] = ['0 - No', '1 - Yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is CCA column:\n",
    "- 0 - Sports\n",
    "- 1 - Arts\n",
    "- 2 - Clubs\n",
    "- 3 - None\n",
    "\n",
    "Take into account different format of the same pattern (uppercases/lowercases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Sports' -> 0, 'Arts' -> 1, \"Clubs\" -> 2 and \"None\" -> 3 in CCA column\n",
    "cleaned_score_data[\"CCA\"] = cleaned_score_data[\"CCA\"].str.lower().replace({\"sports\": 0, \"arts\": 1, \"clubs\": 2, \"none\": 3})\n",
    "\n",
    "# Check if anything is missed from CCA column by checking for unique values\n",
    "cleaned_score_data[\"CCA\"].unique()\n",
    "\n",
    "# Add conversion to dict\n",
    "convert_label_dict[\"CCA\"] = ['0 - Sports', '1 - Arts', '2 - Clubs', '3 - None']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace learning_style column with following format:\n",
    "- 0 - Visual\n",
    "- 1 - Auditory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Visual' -> 0 and 'Auditory' -> 1 in learning_style column\n",
    "cleaned_score_data[\"learning_style\"] = cleaned_score_data[\"learning_style\"].str.lower().replace({\"visual\": 0, \"auditory\": 1})\n",
    "\n",
    "# Check if anything is missed from learning_style column by checking for unique values\n",
    "cleaned_score_data[\"learning_style\"].unique()\n",
    "\n",
    "# Add conversion to dict\n",
    "convert_label_dict[\"learning_style\"] = ['0 - Visual', '1 - Auditory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace tuition column with following format:\n",
    "- 0 - N/No\n",
    "- 1 - Y/Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'No'/'N' -> 0 and 'Yes'/'Y' -> 1 in tuition column\n",
    "cleaned_score_data[\"tuition\"] = cleaned_score_data[\"tuition\"].str.lower().replace({\"no\": 0, \"yes\": 1, \"n\": 0, \"y\": 1})\n",
    "\n",
    "# Check if anything is missed from tuition column by checking for unique values\n",
    "cleaned_score_data[\"tuition\"].unique()\n",
    "\n",
    "# Add conversion to dict\n",
    "convert_label_dict[\"tuition\"] = ['0 - No/N', '1 - Yes/Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace mode_of_transport column with following format:\n",
    "- 0 - Walk\n",
    "- 1 - Public Transport\n",
    "- 2 - Private Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Walk' -> 0, 'Public Transport' -> 1 and \"Private Transport\" -> 2 in mode_of_transport column\n",
    "cleaned_score_data[\"mode_of_transport\"] = cleaned_score_data[\"mode_of_transport\"].str.lower().replace({\"walk\": 0, \"public transport\": 1, \"private transport\": 2})\n",
    "\n",
    "# Check if anything is missed from mode_of_transport column by checking for unique values\n",
    "cleaned_score_data[\"mode_of_transport\"].unique()\n",
    "\n",
    "# Add conversion to dict\n",
    "convert_label_dict[\"mode_of_transport\"] = ['0 - Walk', '1 - Public Transport', '2 - Private Transport']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since sleep_time & wake_time columns are the only ones that are of non int/float values, they will need to be converted to numeric value <br>\n",
    "These two columns will be used to calculate the number of hours of sleep each student has to try and get a correlation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to calculate sleep hours\n",
    "def cal_sleep_hours(sleep_time, wake_time):\n",
    "    # Convert sleep_time and wake_time to datetime objects\n",
    "    sleep_time = datetime.strptime(sleep_time, '%H:%M')\n",
    "    wake_time = datetime.strptime(wake_time, \"%H:%M\")\n",
    "\n",
    "    # If wake_time is earlier than sleep_time, assume wake_time is on the next day\n",
    "    if wake_time < sleep_time:\n",
    "        wake_time += pd.Timedelta(days = 1)\n",
    "\n",
    "    # Calculate difference in hours\n",
    "    sleep_duration = (wake_time - sleep_time).total_seconds() / 3600 # Convert seconds to hours\n",
    "\n",
    "    return sleep_duration\n",
    "\n",
    "# Apply function to calculate sleep hours for each row\n",
    "cleaned_score_data[\"sleep_hours\"] = cleaned_score_data.apply(lambda row: cal_sleep_hours(row[\"sleep_time\"], row[\"wake_time\"]), axis = 1)\n",
    "\n",
    "# Drop sleep_time and wake_time columns since they cannot be correlated\n",
    "time_col_list = [\"sleep_time\", \"wake_time\"]\n",
    "cleaned_score_data = cleaned_score_data.drop(columns = time_col_list)\n",
    "\n",
    "# Check updated DataFrame\n",
    "cleaned_score_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can now be used to generate summary statistics to check on the mean, median, 25%, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics from 'score' DataFrame\n",
    "summary_stats = cleaned_score_data.describe()\n",
    "\n",
    "# Display summary statistics\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze the patterns and distributions in 'score' DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histograms for each numeric column against final_test to understand their distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the result column name\n",
    "result_col = \"final_test\"\n",
    "\n",
    "# Select numeric columns only (excluding the result column)\n",
    "numeric_cols = cleaned_score_data.select_dtypes(include=['float', 'int']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col != result_col]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    sns.scatterplot(data = cleaned_score_data, x = col, y = result_col, hue = col)\n",
    "    plt.title(f\"Distribution of {col} against result\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(result_col)\n",
    "    if col in convert_label_dict:\n",
    "        plt.legend(labels = convert_label_dict[col], title = \"Legend:\", loc = \"best\")\n",
    "    else:\n",
    "        plt.legend(title = \"Legend:\", loc = \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As direct_admission, CCA, learning_style, tuition and mode_of_transport columns cannot be used to draw any meaningful correlation results, they will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate list with columns to be dropped\n",
    "exclude_col_list = [\"direct_admission\", \"CCA\", \"learning_style\", \"tuition\", \"mode_of_transport\"]\n",
    "\n",
    "# Drop columns\n",
    "fil_score_data = cleaned_score_data.drop(columns = exclude_col_list)\n",
    "\n",
    "# Check DataFrame\n",
    "fil_score_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check scatterplot of remaining data to determine correlation again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns only (excluding the result column)\n",
    "new_numeric_cols = fil_score_data.select_dtypes(include=['float', 'int']).columns\n",
    "new_numeric_cols = [col for col in new_numeric_cols if col != result_col]\n",
    "\n",
    "for col in new_numeric_cols:\n",
    "    sns.scatterplot(data = fil_score_data, x = col, y = result_col, hue = col)\n",
    "    plt.title(f\"Distribution of {col} against result\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(result_col)\n",
    "    if col in convert_label_dict:\n",
    "        plt.legend(labels = convert_label_dict[col], title = \"Legend:\", loc = \"best\")\n",
    "    else:\n",
    "        plt.legend(title = \"Legend:\", loc = \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform matrix correlation between different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_corr_matrix = fil_score_data.corr()\n",
    "sns.heatmap(fil_corr_matrix, annot = True, cmap = \"coolwarm\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
